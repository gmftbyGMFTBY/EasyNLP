temp: 1.
# five for restoration-200k is enough
full_turn_length: 100
test_interval: 0.01
multi_ctx: 1
min_conv_length: 3
hidden_dropout_ratio: 0.3
data_filter_size: 650000

# data augmentation parameters
alpha_sentence_swap: 5
alpha_synonym_replacement: 0.1
alpha_random_insertion: 0.1
alpha_random_swap: 0.15
alpha_random_deletion: 0.15
aug_num: 2

# train configuration
train:
    load_param: true
    # load_param: false
    lr: 0.00005
    grad_clip: 5.0
    seed: 0
    batch_size: 64
    max_len: 256
    res_max_len: 64
    epoch: 5
    warmup_ratio: 0.
    stop_train: false
    stop_train_trigger:
        R10@1: 35.
    checkpoint: 
        # path: bert-post/best_nspmlm.pt
        # path: bert-fp/best_bert-base-chinese.pt
        path: bert-fp-comp/best_bert-base-chinese.pt
        # path: bert-fp-multi/best_bert-base-chinese.pt
        # path: dual-bert-pt/best_bert-base-chinese.pt
        # path: bert-fp-no-cls/best_bert-base-chinese.pt
        # path: bert-fp-mono/best_bert-base-chinese.pt
        # path: bert-fp-mono/best_bert-base-uncased.pt
        # path: simcse/best_bert-base-chinese.pt
        is_load: true

# test configuration
test:
    seed: 0
    batch_size: 1
    max_len: 256
    res_max_len: 64

# inference configuration
inference:
    seed: 0
    batch_size: 128 
    max_len: 64
    ctx_max_len: 256
    topk: 20
    # index_type: IVF3722,Flat
    # index_type: IVF6509,Flat
    # index_type: IVF931,Flat
    index_type: Flat
    # index_type: LSH
    index_nprobe: 5
    dimension: 768
