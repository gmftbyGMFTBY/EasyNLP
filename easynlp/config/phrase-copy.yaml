hard_margin: 5.
valid_during_training: false
is_step_for_training: true
total_step: 200010
save_every: 10000
temp: 0.01
dropout: 0.1
min_phrase_length: 3
max_phrase_length: 16
max_doc_num: 16
# 128
doc_max_length: 128
max_doc_length: 128
max_window_size: 16
max_hn_num: 3
# for hard negative
left_window_size: 2
right_window_size: 16
replace_ratio: 0.5

# interaction parameters
nhead: 12
nlayer: 3
inter_topk: 128

index_type: IVF10000,PQ16
# index_type: Flat
dimension: 768
index_nprobe: 100

token_cl_sample_num: 128
margin: 0.5
max_moving_step: 3
min_moving_step: 10
# english
gray_cand_num: 8
hard_neg_for_each_doc: 10
optimize_bert_step: 5
optimize_bert_time: 50
bert_chunk_size: 128

# 128
max_doc_size: 256
# maximum gpt2 samples size
max_sample_num: 32
buffer_size: 81920
phrase_tokenizer: 
    zh: /apdcephfs/share_916081/johntianlan/bert-base-chinese
    en: /apdcephfs/share_916081/johntianlan/bert-base-cased
    # zh: /apdcephfs/share_916081/johntianlan/gpt2-chinese-cluecorpussmall
    # en: /apdcephfs/share_916081/johntianlan/gpt2_english
phrase_encoder_model: 
    zh: /apdcephfs/share_916081/johntianlan/bert-base-chinese
    en: /apdcephfs/share_916081/johntianlan/bert-base-cased
    # zh: /apdcephfs/share_916081/johntianlan/gpt2-chinese-cluecorpussmall
    # en: /apdcephfs/share_916081/johntianlan/gpt2_english
tokenizer: 
    zh: /apdcephfs/share_916081/johntianlan/gpt2-chinese-cluecorpussmall
    # en: /apdcephfs/share_916081/johntianlan/bert-base-cased
    en: /apdcephfs/share_916081/johntianlan/gpt2_english
pretrained_model: 
    zh: /apdcephfs/share_916081/johntianlan/gpt2-chinese-cluecorpussmall
    en: /apdcephfs/share_916081/johntianlan/gpt2_english

# train configuration
train:
    load_param: true
    lr: 0.00005
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_len: 512 
    warmup_ratio: 0.
    epoch: 5
    iter_to_accumulate: 1
    checkpoint: 
        path: bert-post/best_nspmlm.pt
        is_load: false

# test configuration
test:
    seed: 0
    batch_size: 1
    prefix_length_rate: 0.5
    max_len: 512

inference:
    seed: 0
    batch_size: 256
    inf_phrase_min_len: 4
    inf_phrase_max_len: 32
    max_len: 512
    index_type: IVF10000,PQ16
    # index_type: Flat
    dimension: 768
    index_nprobe: 10000
